<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Fullscreen Face Detection Corrected</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
    }
    video, canvas {
      position: absolute;
      object-fit: contain; /* preserve aspect ratio */
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    let model;

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await new Promise(resolve => video.onloadedmetadata = () => resolve(video));
      video.play();
      resizeCanvas();
    }

    function resizeCanvas() {
      const videoAspect = video.videoWidth / video.videoHeight;
      const windowAspect = window.innerWidth / window.innerHeight;
      let width, height;

      if (windowAspect > videoAspect) {
        height = window.innerHeight;
        width = height * videoAspect;
      } else {
        width = window.innerWidth;
        height = width / videoAspect;
      }

      canvas.width = width;
      canvas.height = height;

      canvas.style.left = `${(window.innerWidth - width) / 2}px`;
      canvas.style.top = `${(window.innerHeight - height) / 2}px`;

      video.style.width = `${width}px`;
      video.style.height = `${height}px`;
      video.style.left = canvas.style.left;
      video.style.top = canvas.style.top;
    }

    async function detectFaces() {
      const predictions = await model.estimateFaces(video, false);
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      predictions.forEach(prediction => {
        const start = prediction.topLeft;
        const end = prediction.bottomRight;
        ctx.strokeStyle = 'lime';
        ctx.lineWidth = 4;
        ctx.strokeRect(
          start[0] * (canvas.width / video.videoWidth),
          start[1] * (canvas.height / video.videoHeight),
          (end[0] - start[0]) * (canvas.width / video.videoWidth),
          (end[1] - start[1]) * (canvas.height / video.videoHeight)
        );
      });
      requestAnimationFrame(detectFaces);
    }

    async function run() {
      await setupCamera();
      model = await blazeface.load();
      detectFaces();
    }

    window.addEventListener('resize', resizeCanvas);

    run();
  </script>
</body>
</html>
